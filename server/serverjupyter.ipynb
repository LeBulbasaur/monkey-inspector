{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e9469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import *\n",
    "from flask_cors import CORS\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dda1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"malpytest7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098c0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(os.path.join('models', model, 'pipeline.config'))\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join('models', model, 'ckpt-4')).expect_partial()\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(os.path.join('annotations', 'label_map.pbtxt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2bcd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbc8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec(IMAGE_PATH):\n",
    "    img = cv2.imread(IMAGE_PATH)\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.4,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.savefig(\"mygraph.png\")\n",
    "    outcome = detections[\"detection_classes\"][0]+1\n",
    "    #print(outcome)\n",
    "    return outcome\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa38466",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = \"../client/src/uploads\"\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpeg', 'jpg'}\n",
    "app = Flask(__name__, static_folder='../client/src')\n",
    "CORS(app)\n",
    "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8f09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "        filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfbb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6519d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/upload\", methods=[\"POST\", \"GET\"])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files:\n",
    "            data = {\"message\": 0, \"monkey\" : 0}\n",
    "            return jsonify(data)\n",
    "        file = request.files['file']\n",
    "        if file.filename == '':\n",
    "            data = {\"message\": 0, \"monkey\" : 0}\n",
    "            return jsonify(data)\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "            file.save(path)\n",
    "            monkey_id = rec(path)\n",
    "            print(monkey_id)\n",
    "            data = {\"message\": 1, \"monkey\" : int(monkey_id)}\n",
    "            return jsonify(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8a45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:3000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Jan/2023 10:53:01] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:53:11] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:53:26] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:53:28] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:53:43] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:53:45] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:53:50] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:53:53] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:53:59] \"OPTIONS /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function detect_fn at 0x0000025AD45D6C20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:54:02] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:54:38] \"OPTIONS /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function detect_fn at 0x0000025AD45D6C20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:54:40] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:54:45] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:54:48] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:54:51] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:54:54] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:55:00] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:55:01] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:55:08] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jan/2023 10:55:14] \"OPTIONS /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jan/2023 10:55:15] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(port=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60624cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
